TRAIN:
  train_script_path: E:\stablediffusion\novelai-webui-aki-v2\extensions\kohya-sd-scripts-webui\kohya_ss\train_network.py # your train script path 
  pretrained_model_name_or_path: E:\stablediffusion\novelai-webui-aki-v2\models\Stable-diffusion\AnythingV5_v5PrtRE.safetensors
  train_data_dir: F:\train_data_dir\default
  caption_extension: .txt
  resolution: 1024,1024
  cache_latents: true
  enable_bucket: true
  min_bucket_reso: 256
  max_bucket_reso: 2048
  bucket_reso_steps: 64
  in_json: F:\train_data_dir\default\tags.json
  dataset_repeats: 50
  output_dir: F:\train_data_dir\default_lion_with_dim16_alpha8
  output_name: default_style
  save_every_n_epochs: 1
  train_batch_size: 1
  xformers: true
  max_train_epochs: 5
  max_data_loader_n_workers: 8
  gradient_accumulation_steps: 1
  mixed_precision: fp16
  clip_skip: 2
  optimizer_type: Lion
  lr_scheduler: cosine_with_restarts
  lr_scheduler_num_cycles: 1
  lr_scheduler_power: 1.0
  network_module: networks.lora
  text_encoder_lr: 7e-6
  unet_lr: 6e-5
  network_dim: 16
  network_alpha: 8

# you can set your max_train_steps or other key to very small to test recipes whether can run through the whole exps to avoid the mistakes while training a long time
DEBUG:
  train_script_path: E:\stablediffusion\novelai-webui-aki-v2\extensions\kohya-sd-scripts-webui\kohya_ss\train_network.py 
  pretrained_model_name_or_path: E:\stablediffusion\novelai-webui-aki-v2\models\Stable-diffusion\AnythingV5_v5PrtRE.safetensors
  train_data_dir: F:\train_data_dir\default
  caption_extension: .txt
  resolution: 512,512
  cache_latents: true
  enable_bucket: true
  min_bucket_reso: 256
  max_bucket_reso: 1024
  bucket_reso_steps: 64
  in_json: F:\train_data_dir\default\tags.json
  dataset_repeats: 5
  output_dir: F:\train_data_dir\default_lion_with_dim16_alpha8
  output_name: default_character
  save_every_n_epochs: 5
  train_batch_size: 1
  xformers: true
  max_train_steps: 2
  max_data_loader_n_workers: 8
  gradient_accumulation_steps: 1
  mixed_precision: fp16
  clip_skip: 2
  sample_every_n_epochs: 5
  sample_prompts: F:\train_data_dir\default\prompts.txt
  sample_sampler: euler_a
  optimizer_type: Lion
  lr_scheduler: cosine_with_restarts
  lr_scheduler_num_cycles: 1
  lr_scheduler_power: 1.0
  network_module: networks.lora
  text_encoder_lr: 7e-6
  unet_lr: 6e-5
  network_dim: 16
  network_alpha: 8
